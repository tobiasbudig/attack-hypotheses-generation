{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing neccessary modules and packages \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  read in data\n",
    "- List of relative frequencies of techniques in X_small\n",
    "- y_train to train the GA\n",
    "- y_validation to later test the GA result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1548.002</th>\n",
       "      <td>0.0047824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134</th>\n",
       "      <td>0.00167384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134.002</th>\n",
       "      <td>0.00167384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134.001</th>\n",
       "      <td>0.00143472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1087.002</th>\n",
       "      <td>0.00215208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102</th>\n",
       "      <td>0.00047824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.002</th>\n",
       "      <td>0.00502152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.001</th>\n",
       "      <td>0.00167384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.003</th>\n",
       "      <td>0.00071736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047</th>\n",
       "      <td>0.00884744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 prop\n",
       "T1548.002   0.0047824\n",
       "T1134      0.00167384\n",
       "T1134.002  0.00167384\n",
       "T1134.001  0.00143472\n",
       "T1087.002  0.00215208\n",
       "...               ...\n",
       "T1102      0.00047824\n",
       "T1102.002  0.00502152\n",
       "T1102.001  0.00167384\n",
       "T1102.003  0.00071736\n",
       "T1047      0.00884744\n",
       "\n",
       "[192 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in excel with techniques and probabilities, sheet X removed latest 20%\n",
    "X = pd.read_excel(\"../Data for algorithms.xlsx\", sheet_name=\"X\", index_col=\"ID\")\n",
    "X_old = pd.read_excel(\"../reduced_table_with_timestamps_and_props.xlsx\", sheet_name=\"X\", index_col=\"ID\")\n",
    "\n",
    "# extract probabilities from excel and save as pd data frame\n",
    "probs = pd.DataFrame(X.iloc[0])[1:]\n",
    "probs_old = pd.DataFrame(X_old.iloc[0])[1:]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>S0471</th>\n",
       "      <th>S0470</th>\n",
       "      <th>S0469</th>\n",
       "      <th>S0473</th>\n",
       "      <th>S0475</th>\n",
       "      <th>S0477</th>\n",
       "      <th>S0476</th>\n",
       "      <th>S0481</th>\n",
       "      <th>S0482</th>\n",
       "      <th>S0483</th>\n",
       "      <th>...</th>\n",
       "      <th>S0590</th>\n",
       "      <th>S0593</th>\n",
       "      <th>S0591</th>\n",
       "      <th>S0592</th>\n",
       "      <th>S0595</th>\n",
       "      <th>S0594</th>\n",
       "      <th>S0596</th>\n",
       "      <th>S0597</th>\n",
       "      <th>S0599</th>\n",
       "      <th>S0600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1548.002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134.002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134.001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1087.002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID         S0471  S0470  S0469  S0473  S0475  S0477  S0476  S0481  S0482  \\\n",
       "T1548.002      0      0      0      0      0      0      0      0      0   \n",
       "T1134          0      0      0      0      0      0      0      0      0   \n",
       "T1134.002      0      0      0      0      0      0      0      0      0   \n",
       "T1134.001      0      0      0      0      0      0      0      0      0   \n",
       "T1087.002      0      0      0      0      0      0      1      0      0   \n",
       "...          ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "T1102          0      0      0      0      0      0      0      0      0   \n",
       "T1102.002      0      0      0      0      0      0      0      0      0   \n",
       "T1102.001      0      0      0      0      0      0      0      0      0   \n",
       "T1102.003      0      0      0      0      0      0      0      0      0   \n",
       "T1047          0      0      0      0      0      0      1      0      0   \n",
       "\n",
       "ID         S0483  ...  S0590  S0593  S0591  S0592  S0595  S0594  S0596  S0597  \\\n",
       "T1548.002      0  ...      0      0      0      0      0      0      0      0   \n",
       "T1134          0  ...      0      0      0      0      0      0      0      0   \n",
       "T1134.002      0  ...      0      0      0      0      0      0      0      0   \n",
       "T1134.001      0  ...      0      0      0      0      0      0      0      0   \n",
       "T1087.002      1  ...      0      0      0      0      0      0      0      0   \n",
       "...          ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "T1102          0  ...      0      0      0      0      0      0      0      0   \n",
       "T1102.002      0  ...      0      0      0      0      0      0      0      0   \n",
       "T1102.001      0  ...      0      0      0      0      0      0      0      0   \n",
       "T1102.003      0  ...      0      0      0      0      0      0      0      0   \n",
       "T1047          1  ...      0      0      0      0      0      0      0      0   \n",
       "\n",
       "ID         S0599  S0600  \n",
       "T1548.002      0      0  \n",
       "T1134          0      0  \n",
       "T1134.002      0      0  \n",
       "T1134.001      0      0  \n",
       "T1087.002      0      0  \n",
       "...          ...    ...  \n",
       "T1102          0      1  \n",
       "T1102.002      0      0  \n",
       "T1102.001      0      0  \n",
       "T1102.003      0      0  \n",
       "T1047          0      0  \n",
       "\n",
       "[192 rows x 89 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in excel with newest 20 percent of techniques for evaluation\n",
    "y_train = pd.read_excel(\"../Data for algorithms.xlsx\", sheet_name=\"Y\", index_col=\"ID\")\n",
    "y_train = y_train.drop(y_train.tail(2).index, axis=0)\n",
    "y_train = y_train.drop(['created'], axis = 1).T\n",
    "y_train_old = pd.read_excel(\"../reduced_table_with_timestamps_and_props.xlsx\", sheet_name=\"y\", index_col=\"ID\")\n",
    "y_train_old = y_train_old.drop(y_train_old.tail(2).index, axis=0)\n",
    "y_train_old = y_train_old.drop(['created'], axis = 1).T\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1548.002</th>\n",
       "      <th>T1134</th>\n",
       "      <th>T1134.002</th>\n",
       "      <th>T1134.001</th>\n",
       "      <th>T1087.002</th>\n",
       "      <th>T1087.003</th>\n",
       "      <th>T1087.001</th>\n",
       "      <th>T1071</th>\n",
       "      <th>T1071.004</th>\n",
       "      <th>T1071.002</th>\n",
       "      <th>...</th>\n",
       "      <th>T1078.003</th>\n",
       "      <th>T1125</th>\n",
       "      <th>T1497</th>\n",
       "      <th>T1497.001</th>\n",
       "      <th>T1497.003</th>\n",
       "      <th>T1102</th>\n",
       "      <th>T1102.002</th>\n",
       "      <th>T1102.001</th>\n",
       "      <th>T1102.003</th>\n",
       "      <th>T1047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1548.002</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.229236</td>\n",
       "      <td>0.347270</td>\n",
       "      <td>0.194084</td>\n",
       "      <td>-0.025795</td>\n",
       "      <td>0.114904</td>\n",
       "      <td>0.089907</td>\n",
       "      <td>0.055471</td>\n",
       "      <td>-0.041135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089907</td>\n",
       "      <td>0.134809</td>\n",
       "      <td>0.063056</td>\n",
       "      <td>0.134809</td>\n",
       "      <td>-0.025795</td>\n",
       "      <td>-0.018189</td>\n",
       "      <td>-0.008821</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134</th>\n",
       "      <td>0.141401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.271503</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>0.235099</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>0.265323</td>\n",
       "      <td>0.176950</td>\n",
       "      <td>-0.032415</td>\n",
       "      <td>-0.023882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>0.045358</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>-0.036913</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>-0.019896</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>0.150957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134.002</th>\n",
       "      <td>0.229236</td>\n",
       "      <td>0.271503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138756</td>\n",
       "      <td>0.363961</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>0.188934</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>-0.032415</td>\n",
       "      <td>0.098542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>0.127630</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>-0.036913</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>-0.019896</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>0.084696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1134.001</th>\n",
       "      <td>0.347270</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>0.138756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118073</td>\n",
       "      <td>-0.013845</td>\n",
       "      <td>0.045196</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>0.069602</td>\n",
       "      <td>-0.022079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>0.054611</td>\n",
       "      <td>-0.017005</td>\n",
       "      <td>0.232086</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.032512</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>0.027253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1087.002</th>\n",
       "      <td>0.194084</td>\n",
       "      <td>0.235099</td>\n",
       "      <td>0.363961</td>\n",
       "      <td>0.118073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017030</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>0.126432</td>\n",
       "      <td>-0.027157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>-0.020916</td>\n",
       "      <td>-0.041975</td>\n",
       "      <td>-0.017030</td>\n",
       "      <td>-0.012008</td>\n",
       "      <td>0.035935</td>\n",
       "      <td>-0.022624</td>\n",
       "      <td>-0.014727</td>\n",
       "      <td>0.180030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102</th>\n",
       "      <td>-0.018189</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.012008</td>\n",
       "      <td>-0.007949</td>\n",
       "      <td>-0.021355</td>\n",
       "      <td>-0.007949</td>\n",
       "      <td>-0.017205</td>\n",
       "      <td>-0.012676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007949</td>\n",
       "      <td>-0.019592</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.019592</td>\n",
       "      <td>-0.007949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018665</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>-0.006874</td>\n",
       "      <td>-0.025384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.002</th>\n",
       "      <td>-0.008821</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>-0.032512</td>\n",
       "      <td>0.035935</td>\n",
       "      <td>-0.026471</td>\n",
       "      <td>0.063906</td>\n",
       "      <td>-0.026471</td>\n",
       "      <td>-0.057296</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026471</td>\n",
       "      <td>0.080174</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.128648</td>\n",
       "      <td>-0.026471</td>\n",
       "      <td>-0.018665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136523</td>\n",
       "      <td>-0.022892</td>\n",
       "      <td>0.032586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.001</th>\n",
       "      <td>0.053566</td>\n",
       "      <td>-0.019896</td>\n",
       "      <td>-0.019896</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>-0.022624</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>-0.040235</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>0.059899</td>\n",
       "      <td>-0.023882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>-0.036913</td>\n",
       "      <td>0.138756</td>\n",
       "      <td>0.127630</td>\n",
       "      <td>-0.014976</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>0.136523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>0.018435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1102.003</th>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>-0.011974</td>\n",
       "      <td>-0.014727</td>\n",
       "      <td>-0.009749</td>\n",
       "      <td>-0.026191</td>\n",
       "      <td>-0.009749</td>\n",
       "      <td>-0.021101</td>\n",
       "      <td>-0.015546</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009749</td>\n",
       "      <td>-0.024029</td>\n",
       "      <td>0.226724</td>\n",
       "      <td>-0.024029</td>\n",
       "      <td>-0.009749</td>\n",
       "      <td>-0.006874</td>\n",
       "      <td>-0.022892</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1047</th>\n",
       "      <td>0.117351</td>\n",
       "      <td>0.150957</td>\n",
       "      <td>0.084696</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.180030</td>\n",
       "      <td>0.051284</td>\n",
       "      <td>0.146465</td>\n",
       "      <td>0.051284</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>-0.001732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.060929</td>\n",
       "      <td>0.098722</td>\n",
       "      <td>0.098344</td>\n",
       "      <td>0.138568</td>\n",
       "      <td>-0.025384</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>-0.031133</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           T1548.002     T1134  T1134.002  T1134.001  T1087.002  T1087.003  \\\n",
       "T1548.002   1.000000  0.141401   0.229236   0.347270   0.194084  -0.025795   \n",
       "T1134       0.141401  1.000000   0.271503  -0.018394   0.235099  -0.014976   \n",
       "T1134.002   0.229236  0.271503   1.000000   0.138756   0.363961  -0.014976   \n",
       "T1134.001   0.347270 -0.018394   0.138756   1.000000   0.118073  -0.013845   \n",
       "T1087.002   0.194084  0.235099   0.363961   0.118073   1.000000  -0.017030   \n",
       "...              ...       ...        ...        ...        ...        ...   \n",
       "T1102      -0.018189 -0.010560  -0.010560  -0.009763  -0.012008  -0.007949   \n",
       "T1102.002  -0.008821  0.050678   0.050678  -0.032512   0.035935  -0.026471   \n",
       "T1102.001   0.053566 -0.019896  -0.019896  -0.018394  -0.022624  -0.014976   \n",
       "T1102.003  -0.022308 -0.012951  -0.012951  -0.011974  -0.014727  -0.009749   \n",
       "T1047       0.117351  0.150957   0.084696   0.027253   0.180030   0.051284   \n",
       "\n",
       "           T1087.001     T1071  T1071.004  T1071.002  ...  T1078.003  \\\n",
       "T1548.002   0.114904  0.089907   0.055471  -0.041135  ...   0.089907   \n",
       "T1134       0.265323  0.176950  -0.032415  -0.023882  ...  -0.014976   \n",
       "T1134.002   0.188934 -0.014976  -0.032415   0.098542  ...  -0.014976   \n",
       "T1134.001   0.045196  0.193164   0.069602  -0.022079  ...   0.193164   \n",
       "T1087.002   0.292055  0.152716   0.126432  -0.027157  ...   0.152716   \n",
       "...              ...       ...        ...        ...  ...        ...   \n",
       "T1102      -0.021355 -0.007949  -0.017205  -0.012676  ...  -0.007949   \n",
       "T1102.002   0.063906 -0.026471  -0.057296   0.029918  ...  -0.026471   \n",
       "T1102.001  -0.040235 -0.014976   0.059899  -0.023882  ...  -0.014976   \n",
       "T1102.003  -0.026191 -0.009749  -0.021101  -0.015546  ...  -0.009749   \n",
       "T1047       0.146465  0.051284   0.006045  -0.001732  ...   0.225852   \n",
       "\n",
       "              T1125     T1497  T1497.001  T1497.003     T1102  T1102.002  \\\n",
       "T1548.002  0.134809  0.063056   0.134809  -0.025795 -0.018189  -0.008821   \n",
       "T1134      0.045358 -0.018394  -0.036913  -0.014976 -0.010560   0.050678   \n",
       "T1134.002  0.127630 -0.018394  -0.036913  -0.014976 -0.010560   0.050678   \n",
       "T1134.001  0.054611 -0.017005   0.232086   0.193164 -0.009763  -0.032512   \n",
       "T1087.002  0.030789 -0.020916  -0.041975  -0.017030 -0.012008   0.035935   \n",
       "...             ...       ...        ...        ...       ...        ...   \n",
       "T1102     -0.019592 -0.009763  -0.019592  -0.007949  1.000000  -0.018665   \n",
       "T1102.002  0.080174  0.060079   0.128648  -0.026471 -0.018665   1.000000   \n",
       "T1102.001 -0.036913  0.138756   0.127630  -0.014976 -0.010560   0.136523   \n",
       "T1102.003 -0.024029  0.226724  -0.024029  -0.009749 -0.006874  -0.022892   \n",
       "T1047      0.060929  0.098722   0.098344   0.138568 -0.025384   0.032586   \n",
       "\n",
       "           T1102.001  T1102.003     T1047  \n",
       "T1548.002   0.053566  -0.022308  0.117351  \n",
       "T1134      -0.019896  -0.012951  0.150957  \n",
       "T1134.002  -0.019896  -0.012951  0.084696  \n",
       "T1134.001  -0.018394  -0.011974  0.027253  \n",
       "T1087.002  -0.022624  -0.014727  0.180030  \n",
       "...              ...        ...       ...  \n",
       "T1102      -0.010560  -0.006874 -0.025384  \n",
       "T1102.002   0.136523  -0.022892  0.032586  \n",
       "T1102.001   1.000000  -0.012951  0.018435  \n",
       "T1102.003  -0.012951   1.000000 -0.031133  \n",
       "T1047       0.018435  -0.031133  1.000000  \n",
       "\n",
       "[192 rows x 192 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in correlation matrix\n",
    "#corr_mat = pd.read_excel(\"../Data for algorithms.xlsx\", sheet_name=\"X_phi_techniques\")\n",
    "#corr_mat = corr_mat.set_index(\"ID\")\n",
    "corr_mat = X.corr()\n",
    "corr_mat_old = X_old.corr()\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting global variables for algorithm\n",
    "population_size = 20 \n",
    "maximum_generation = 300, \n",
    "prob_of_ones= 12.5 / len(probs) # 12.5 is mean of ones in X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create helper functions\n",
    "- create_starting_population\n",
    "- calculate_fitness\n",
    "- select_individual_by_tournament\n",
    "- select_individual_by_roulette\n",
    "- breed_by_crossover_1point\n",
    "- breed_by_crossover_2point\n",
    "- breed_by_crossover_uniform\n",
    "- randomly_mutate_population\n",
    "- calculate_F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a starting population by drawing zeros and ones randomly. Chance for ones is prob_of_ones\n",
    "# individuals: int is number of individuals (=software) to be generated\n",
    "# length_of_techniques: int\n",
    "# percent_of_ones: float\n",
    "def create_starting_population(individuals, length_of_techniques, prob_of_ones=prob_of_ones):\n",
    "    \n",
    "    size = (individuals, length_of_techniques)\n",
    "    probability = np.array([ 1 - prob_of_ones, prob_of_ones])\n",
    "    \n",
    "    population = np.random.choice([0,1], size=size, p=probability)\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example starting population\n",
    "# print (create_starting_population(6, len(probs)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate fitness of every individual in the current population\n",
    "def calculate_fitness(individuals, probs, corr_mat, lamda_balance = 0.2, bonus_factor = 135, penalty_factor = 12, print_out = False):\n",
    "    \n",
    "    len_pop = len(probs)\n",
    "    \n",
    "    individuals = np.array(individuals) # individuals = 6x269\n",
    "    probs = np.array(probs) # array with probabilities 269x1\n",
    "    ones = np.ones(len_pop) # number of ones 269x1\n",
    "    \n",
    "    occurrences = (individuals @ ones) # number of ones in individual 6x1\n",
    "    P = individuals # 6x269\n",
    "    \n",
    "    corr = np.array(corr_mat).reshape(len_pop,len_pop)\n",
    "    np.fill_diagonal(corr, 0) # 269x269, correlation matrix with 0 self covariance\n",
    "    A = (P @ corr) # 6x269\n",
    "    K = (P @ A.T) # 6x6\n",
    "    corr_term = K.diagonal()/len_pop # diagonal elements of matrix K \n",
    "\n",
    "    \n",
    "    prob_term = (individuals @ probs) # a includes values between 0 and 1\n",
    "#     expected_techniques = np.rint(np.random.normal(11,1))\n",
    "#     if expected_techniques < 0:\n",
    "#         expected_techniques = 0\n",
    "    difference = (np.subtract(occurrences, 12.0)) # here random N(11, 6)\n",
    "\n",
    "    pen_1 = (difference**2) * np.sign(difference)/penalty_factor\n",
    "    pen_1[pen_1 < 0] = 0\n",
    "    \n",
    "    bonus = np.copy(difference)/bonus_factor\n",
    "    bonus[bonus > 0] = 0\n",
    "    penalty_term = (pen_1 + bonus)\n",
    "        \n",
    "    if print_out:\n",
    "        print(\"prob_term\")\n",
    "        print(prob_term)\n",
    "        print(\"\")\n",
    "        print(occurrences)\n",
    "        print(\"difference\")\n",
    "        print(difference)\n",
    "        print(\"penalty_term\")\n",
    "        print(penalty_term)\n",
    "        print(\"corr_term\")\n",
    "        print(corr_term)\n",
    "        print(\"len_pop\")\n",
    "        print(len_pop)\n",
    "        print(\"\")\n",
    "        \n",
    "    fitness_scores = ((lamda_balance * prob_term.T + corr_term * (1-lamda_balance)) - penalty_term)\n",
    "    return fitness_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing fitness function\n",
    "# testPop = create_starting_population(6, len(probs))\n",
    "# print('Startpopulation')\n",
    "# print(testPop)\n",
    "\n",
    "# calculate_fitness(testPop, probs, corr_mat, print_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to select individuals by using tournament selection\n",
    "def select_individual_by_tournament(population, scores):\n",
    "    # get population size\n",
    "    population_size = len(scores)\n",
    "\n",
    "    # pick individuals for tournament\n",
    "    fighter_1 = random.randint(0, population_size-1)\n",
    "    fighter_2 = random.randint(0, population_size-1)\n",
    "    \n",
    "    # get fitness score for each individual\n",
    "    fighter_1_fitness = scores[fighter_1]\n",
    "    fighter_2_fitness = scores[fighter_2]\n",
    "    \n",
    "    # identify undividual with highest fitness\n",
    "    # fighter 1 will win if scores are equal\n",
    "    if fighter_1_fitness >= fighter_2_fitness:\n",
    "        winner = fighter_1\n",
    "    else:\n",
    "        winner = fighter_2\n",
    "    \n",
    "    #return the chromsome of the winner\n",
    "    return population[winner, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select individuals by using roulette wheel selection\n",
    "\n",
    "def select_individual_by_roulette(population, k): # list of individuals to select from, number of individuals to select, attribute to use as selection criteria\n",
    "    scores = calculate_fitness(population, probs, corr_mat)\n",
    "    # population vectors convert to the same chromosome and therefore the fitness values convert to the same values\n",
    "    scores_list = []\n",
    "    scores_normalized = scores -min(scores)\n",
    "    if scores_normalized.sum() != 0:\n",
    "        for i in range(len(population)):\n",
    "            fitness_sc = scores_normalized[i]\n",
    "            scores_list.append((i, fitness_sc))\n",
    "    # if sum of normalized fittnes scores is 0 => all fittness scores are the same => uniform distribution\n",
    "    else:\n",
    "        for i in range(len(population)): #Gleichverteilung\n",
    "            fitness_sc = 1/len(population)\n",
    "            scores_list.append((i, fitness_sc))\n",
    "            \n",
    "    scores_df = pd.DataFrame(scores_list, columns =[\"Index\", \"Fitness\"])\n",
    "    \n",
    "    scores_df[\"Fitness\"] = scores_df[\"Fitness\"]/scores_df[\"Fitness\"].sum()\n",
    "\n",
    "    chosen = np.random.choice(scores_df[\"Index\"], size = k, p = scores_df[\"Fitness\"].fillna(0))\n",
    "    winner1 = population[chosen[0], :]\n",
    "    winner2 = population[chosen[1], :]\n",
    "\n",
    "    return winner1, winner2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for executing one point crossover\n",
    "def breed_by_crossover_1point(ind1, ind2):\n",
    "    chromosome_length = min(len(ind1), len(ind2))\n",
    "    crossover_point = random.randint(1, chromosome_length-1)\n",
    "    \n",
    "    ind1[crossover_point:], ind2[crossover_point:] = ind2[crossover_point:], ind1[crossover_point:]\n",
    "    \n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for executin two point crossover\n",
    "def breed_by_crossover_2point(ind1, ind2):\n",
    "    chromosome_length = min(len(ind1), len(ind2))\n",
    "    crossover_point1 = random.randint(1, chromosome_length)\n",
    "    crossover_point2 = random.randint(1, chromosome_length-1)\n",
    "    \n",
    "    if crossover_point2 >= crossover_point1:\n",
    "        crossover_point2 += 1\n",
    "    else: # swapping the two crossover points\n",
    "        crossover_point1, crossover_point2 = crossover_point2, crossover_point1\n",
    "        \n",
    "    ind1[crossover_point1: crossover_point2], ind2[crossover_point1: crossover_point2] \\\n",
    "        = ind2[crossover_point1: crossover_point2], ind1[crossover_point1: crossover_point2]\n",
    "    \n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for executing uniform crossover\n",
    "def breed_by_crossover_uniform(ind1, ind2, indpb):\n",
    "    # parameter indpb is the indipendent probability for each bit to be exchanged\n",
    "    # get length of chromosome\n",
    "    chromosome_length = min(len(ind1), len(ind2))\n",
    "    \n",
    "    for i in range(chromosome_length):\n",
    "        if random.random() < indpb: #add: lower probability that 0 --> 1 than the probability that 1 --> 0\n",
    "             ind1[i], ind2[i] = ind2[i], ind1[i]\n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to mutate population\n",
    "def randomly_mutate_population(population, mutation_probability):\n",
    "    \n",
    "    # apply random mutation\n",
    "        random_mutation_array = np.random.random(size=(population.shape))\n",
    "        \n",
    "        random_mutation_boolean = random_mutation_array <= mutation_probability\n",
    "\n",
    "        population[random_mutation_boolean] = np.logical_not(population[random_mutation_boolean])\n",
    "        \n",
    "        # return mutation population\n",
    "        return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to combine scores, occurrences and population\n",
    "import operator\n",
    "class result:\n",
    "    def __init__(self, score, occurences, population):\n",
    "        self.score = score\n",
    "        self.occurences = occurences\n",
    "        self.population = population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluation of results from main algorithm\n",
    "# read in the y_train data set and the predicted software\n",
    "\n",
    "def calculate_F_score(y_train: pd.DataFrame, predicted_sw: np.array, do_print=False):    \n",
    "    #print(type(y_train), type(predicted_sw))\n",
    "    assert y_train.shape[0] == predicted_sw.shape[0]\n",
    "    \n",
    "    ones = np.ones(len(y_train))\n",
    "\n",
    "    occurences = np.array(predicted_sw).T @ ones\n",
    "    \n",
    "    F1_list = []\n",
    "    Software_index = 0\n",
    "    \n",
    "    for software in y_train.columns:\n",
    "        sum_s = y_train[software] @ predicted_sw\n",
    "\n",
    "        precision = 0\n",
    "        if occurences != 0:\n",
    "            precision = sum_s/occurences\n",
    "        \n",
    "        number_of_techniques_y = y_train[software] @ ones\n",
    "        recall = 0\n",
    "        if number_of_techniques_y != 0:\n",
    "            recall = sum_s/(number_of_techniques_y)\n",
    "        F1 = 0\n",
    "        if (precision + recall) != 0:\n",
    "            F1 = 2 * precision* recall /(precision + recall)\n",
    "            \n",
    "        F1_list.append(F1)\n",
    "    \n",
    "    return max(F1_list), F1_list.index(max(F1_list)) ,predicted_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main algorithm code\n",
    "# set general parameters\n",
    "\n",
    "# toDo, choose cross alogrithm\n",
    "def run_ga(probs, corr_mat, population_size = 20, maximum_generation = 300, mutation_rate =0.001, lamda_balance = 0.2, bonus_factor = 135, penalty_factor = 12, set_seed=False, print_out=False):\n",
    "    if set_seed:\n",
    "        random.seed(42)\n",
    "        np.random.seed(42)\n",
    "    \n",
    "    chromosome_length = len(probs)\n",
    "    best_score_progress = [] # tracks progress\n",
    "\n",
    "    # create starting population\n",
    "    population = create_starting_population(population_size, chromosome_length)\n",
    "\n",
    "    # print (population)\n",
    "    # display best score in starting population\n",
    "    scores = calculate_fitness(population, probs, corr_mat, lamda_balance = lamda_balance, bonus_factor = bonus_factor, penalty_factor = penalty_factor)\n",
    "    best_score = np.max(scores)\n",
    "\n",
    "    if print_out:\n",
    "        print ('Starting best score: %.1f' %best_score)\n",
    "\n",
    "    # add starting best score to progress tracker\n",
    "    best_score_progress.append(best_score)\n",
    "\n",
    "    # going through the generations of genetic algorithm\n",
    "    for generation in range(maximum_generation):\n",
    "        # create an empty list for new population\n",
    "        new_population = []\n",
    "\n",
    "        # create new popualtion generating two children at a time\n",
    "        for i in range(int(population_size/2)):\n",
    "            #parent1 = select_individual_by_tournament(population, scores)\n",
    "            #parent2 = select_individual_by_tournament(population, scores)\n",
    "            parent1, parent2 = select_individual_by_roulette(population, 2)\n",
    "            #child_1, child_2 = breed_by_crossover_1point(parent_1, parent_2)\n",
    "            #child_1, child_2 = breed_by_crossover_2point(parent_1, parent_2) # Results are not as promising as with the others\n",
    "            child_1, child_2 = breed_by_crossover_uniform(parent1, parent2, 0.5)\n",
    "            new_population.append(child_1)\n",
    "            new_population.append(child_2)\n",
    "\n",
    "        # replace the old population with the new one\n",
    "        population = np.array(new_population)\n",
    "\n",
    "        # apply mutation\n",
    "        population = randomly_mutate_population(population, mutation_rate)\n",
    "\n",
    "        # score best solution, and add to tracker\n",
    "        scores = calculate_fitness(population, probs, corr_mat, lamda_balance = lamda_balance, bonus_factor = bonus_factor, penalty_factor = penalty_factor)\n",
    "        best_score = np.max(scores)\n",
    "        best_score_progress.append(best_score)\n",
    "\n",
    "    # GA has completed required generation number\n",
    "    ones = np.ones(len(probs)) # number of ones 269x1\n",
    "    occurrences = (population @ ones)\n",
    "    if print_out:\n",
    "        print ('End best score %.1f' %best_score)\n",
    "        print (occurrences)\n",
    "\n",
    "        # plot progress\n",
    "        %matplotlib inline\n",
    "        plt.plot(best_score_progress)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Best score (% target)')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print out information about best individuum\n",
    "        print('Best score target generation: %.1f' %best_score)\n",
    "        \n",
    "    max_index_row = np.argmax(scores, axis=0)\n",
    "    \n",
    "    if print_out:\n",
    "        print ('Position in Array:', max_index_row)\n",
    "        print(\"Number of Ones:\", occurrences[max_index_row])\n",
    "        print(\"\")\n",
    "        print(\"Respective Chromosome:\", population[max_index_row] )\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Techniques used:\")\n",
    "        i = 0\n",
    "        for row in probs.index: \n",
    "            if population [max_index_row][i] == 1:\n",
    "                print(row)\n",
    "            i+=1\n",
    "\n",
    "    best_sw = np.tile(population[max_index_row],1) \n",
    "       \n",
    "    \n",
    "    \n",
    "    # sort attribute scores in order to select best X individuums for evaluation\n",
    "    results = []\n",
    "    for i in range(0,len(scores)):\n",
    "    #    print(i)\n",
    "        r1 = result(scores[i], occurrences[i], population[i])\n",
    "        results.append(r1)\n",
    " \n",
    "\n",
    "    sorted_results = sorted(results, key=operator.attrgetter('score'))\n",
    "    predi = sorted_results[-1]\n",
    "    \n",
    "    #print(\"predi\")\n",
    "    #print(predi)\n",
    "    #print(type(predi))\n",
    "    \n",
    "    \n",
    "    #return sorted_results, best_sw\n",
    "    F1, softwareIndex, generatedSoftware = calculate_F_score(y_train, predi.population, do_print=False)\n",
    "    return F1, softwareIndex, generatedSoftware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting best score: 0.1\n",
      "End best score 0.2\n",
      "[11. 11. 13. 11. 12. 11. 11. 11. 11. 12. 12. 13. 11. 13. 11. 12. 12. 11.\n",
      " 11. 12.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score target generation: 0.2\n",
      "Position in Array: 9\n",
      "Number of Ones: 12.0\n",
      "\n",
      "Respective Chromosome: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "\n",
      "Techniques used:\n",
      "T1071.001\n",
      "T1547.001\n",
      "T1059.003\n",
      "T1074.001\n",
      "T1573.001\n",
      "T1546.015\n",
      "T1070.004\n",
      "T1105\n",
      "T1027\n",
      "T1057\n",
      "T1082\n",
      "T1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5217391304347826,\n",
       " 3,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted_results, best_sw = run_ga(probs, corr_mat, print_out=True)\n",
    "run_ga(probs, corr_mat, print_out=True, set_seed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper functions optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 135, 12, 0.001]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamda_balance = 0.2 # 0 - 0.5\n",
    "bonus_factor = 135 # +-20\n",
    "penalty_factor = 12 #+- 5\n",
    "mutation_rate =0.001 # to optimise\n",
    "\n",
    "startValues = [lamda_balance, bonus_factor, penalty_factor, mutation_rate]\n",
    "startValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.01, 0.99), (115, 155), (7, 12), (0.0008, 0.0012))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerBound = [0.01, 115, 7, 0.0008]\n",
    "upperBound = [0.99, 155, 12, 0.0012]\n",
    "\n",
    "bounds = tuple((lowerBound[x], upperBound[x]) for x in range(0,len(startValues)))\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_func(params):\n",
    "    assert len(params) == 4\n",
    "    lamda_balance = params[0]\n",
    "    bonus_factor = params[1]\n",
    "    penalty_factor = params[2]\n",
    "    mutation_rate = params[3]\n",
    "    # ein bester F1 score optimieren ist noch nicht finales Ziel\n",
    "    F1, F1_index, generated_software = run_ga(probs, corr_mat, population_size = 20, maximum_generation = 30, mutation_rate=mutation_rate, lamda_balance = lamda_balance, bonus_factor = bonus_factor, penalty_factor = penalty_factor, set_seed=True, print_out=False)\n",
    "    return - F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_func_without_seed(params):\n",
    "    assert len(params) == 4\n",
    "    lamda_balance = params[0]\n",
    "    bonus_factor = params[1]\n",
    "    penalty_factor = params[2]\n",
    "    mutation_rate = params[3]\n",
    "    # ein bester F1 score optimieren ist noch nicht finales Ziel\n",
    "    return run_ga(probs, corr_mat, population_size = 20, maximum_generation = 30, mutation_rate=mutation_rate, lamda_balance = lamda_balance, bonus_factor = bonus_factor, penalty_factor = penalty_factor, print_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_30iteration(params):\n",
    "    examples_to_save = 30\n",
    "    F1_values = pd.DataFrame([])\n",
    "\n",
    "    for i in range(examples_to_save):\n",
    "        F1, F1_index, generated_software = GA_func_without_seed(params)\n",
    "        F1_values[f\"software_{i}\"] = np.array([F1])\n",
    "        #print(F1)\n",
    "    \n",
    "    mean = pd.DataFrame(F1_values).T[0].describe()[1]\n",
    "    return -mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.41379310344827586"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA_func(startValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37468307175437915"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA_30iteration(startValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimize hyper-parameter of model\n",
    "#### 5.1 local optimizer \"L-BFGS-B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00e-01, 1.35e+02, 1.20e+01, 1.00e-03])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.optimize as sco\n",
    "minimize = sco.minimize(GA_func, x0=startValues, bounds=bounds, method=\"L-BFGS-B\", options={\"gtol\": 1e-12, \"ftol\":1e-12})\n",
    "minimize.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 global optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_annealing = sco.dual_annealing(GA_30iteration, x0=startValues, bounds=bounds, maxiter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.27924418e-01, 1.37669722e+02, 7.76073210e+00, 9.82359116e-04])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_annealing.x #[7.86555160e-01, 1.18671590e+02, 1.06715895e+01, 1.01544190e-03], [6.73360781e-01, 1.21289711e+02, 9.73594655e+00, 9.69407589e-04], [9.27924418e-01, 1.37669722e+02, 7.76073210e+00, 9.82359116e-04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA_30iteration(dual_annealing.x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Save series of generated softwares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dual_annealing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-2e72c3d01658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmaxIndexValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples_to_save\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mF1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerated_software\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGA_func_without_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#dual_annealing.x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# y-train muss hinzugefÃ¼gt werden!!!!!!!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdf_to_save\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"software_{i}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerated_software\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dual_annealing' is not defined"
     ]
    }
   ],
   "source": [
    "examples_to_save = 30\n",
    "df_to_save = pd.DataFrame([])\n",
    "F1_values = pd.DataFrame([])\n",
    "maxIndexValues = pd.DataFrame([])\n",
    "for i in range(examples_to_save):\n",
    "    F1, maxIndex, generated_software = GA_func_without_seed(dual_annealing.x) #dual_annealing.x\n",
    "    # y-train muss hinzugefÃ¼gt werden!!!!!!!!!\n",
    "    df_to_save[f\"software_{i}\"] = generated_software\n",
    "    print(F1)\n",
    "    F1_values[f\"software_{i}\"] = np.array([F1])\n",
    "    maxIndexValues[f\"software_{i}\"] = np.array([maxIndex])\n",
    "\n",
    "print(\"\")\n",
    "print(pd.DataFrame(F1_values).T[0].describe()[1])\n",
    "maxIndexValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.append(F1_values).append(maxIndexValues).to_excel('output4.xlsx', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_func_without_seed_old(params):\n",
    "    assert len(params) == 4\n",
    "    lamda_balance = params[0]\n",
    "    bonus_factor = params[1]\n",
    "    penalty_factor = params[2]\n",
    "    mutation_rate = params[3]\n",
    "    # ein bester F1 score optimieren ist noch nicht finales Ziel\n",
    "    return run_ga(probs_old, corr_mat_old, population_size = 20, maximum_generation = 30, mutation_rate=mutation_rate, lamda_balance = lamda_balance, bonus_factor = bonus_factor, penalty_factor = penalty_factor, print_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_save = 30\n",
    "df_to_save = pd.DataFrame([])\n",
    "F1_values = pd.DataFrame([])\n",
    "maxIndexValues = pd.DataFrame([])\n",
    "for i in range(examples_to_save):\n",
    "    F1, maxIndex, generated_software = GA_func_without_seed_old(startValues) #dual_annealing.x\n",
    "    # y-train muss hinzugefÃ¼gt werden!!!!!!!!!\n",
    "    df_to_save[f\"software_{i}\"] = generated_software\n",
    "    print(F1)\n",
    "    F1_values[f\"software_{i}\"] = np.array([F1])\n",
    "    maxIndexValues[f\"software_{i}\"] = np.array([maxIndex])\n",
    "\n",
    "print(\"\")\n",
    "print(pd.DataFrame(F1_values).T[0].describe()[1])\n",
    "maxIndexValues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
